{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "from model_gpt import Gpt\n",
    "from data_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "BATCH_SIZE_PER_REPLICA = 8\n",
    "global_batch_size = (BATCH_SIZE_PER_REPLICA *\n",
    "                     mirrored_strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Dense(2, input_shape=(3,))])\n",
    "    optimizer = tf.keras.optimizers.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensors(([1., 2., 3.,], [1., 0.])).repeat(1000).batch(\n",
    "    global_batch_size)\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(dist_inputs):\n",
    "    def step_fn(inputs):\n",
    "        features, labels = inputs\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(features)\n",
    "            #print(logits)\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits=logits, labels=labels)\n",
    "            loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)\n",
    "\n",
    "        print(cross_entropy)\n",
    "        print(\"\\n\")\n",
    "        print(loss)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
    "        return cross_entropy\n",
    "\n",
    "    per_example_losses = mirrored_strategy.experimental_run_v2(\n",
    "            step_fn, args=(dist_inputs,))\n",
    "    mean_loss = mirrored_strategy.reduce(\n",
    "            tf.compat.v2.distribute.ReduceOp.MEAN, per_example_losses, axis=0)\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.05954077 0.05954077 0.05954077 0.05954077 0.05954077 0.05954077\n",
      " 0.05954077 0.05954077], shape=(8,), dtype=float32)\n",
      "\n",
      "\n",
      "tf.Tensor(0.029770385, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.05954077 0.05954077 0.05954077 0.05954077 0.05954077 0.05954077\n",
      " 0.05954077 0.05954077], shape=(8,), dtype=float32)\n",
      "\n",
      "\n",
      "tf.Tensor(0.029770385, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A non-DistributedValues value 8 cannot be reduced with the given reduce op ReduceOp.SUM.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-61dbf4a7290d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmirrored_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdist_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-1d9a5628a6ed>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(dist_inputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m             step_fn, args=(dist_inputs,))\n\u001b[1;32m     22\u001b[0m     mean_loss = mirrored_strategy.reduce(\n\u001b[0;32m---> 23\u001b[0;31m             tf.compat.v2.distribute.ReduceOp.MEAN, per_example_losses, axis=0)\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, reduce_op, value, axis)\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0;31m# TODO(josh11b): Should batch reduce here instead of doing two.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0mnumer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceOp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceOp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, reduce_op, value)\u001b[0m\n\u001b[1;32m   1362\u001b[0m     return self._local_results(\n\u001b[1;32m   1363\u001b[0m         self._reduce_to(reduce_op, value,\n\u001b[0;32m-> 1364\u001b[0;31m                         device_util.current() or \"/device:CPU:0\"))[0]\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_reduce_to\u001b[0;34m(self, reduce_op, value, destinations)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# be 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       return cross_device_ops_lib.reduce_non_distributed_value(\n\u001b[0;32m--> 748\u001b[0;31m           reduce_op, self._device_map, value, destinations)\n\u001b[0m\u001b[1;32m    749\u001b[0m     return self._get_cross_device_ops().reduce(\n\u001b[1;32m    750\u001b[0m         reduce_op, value, destinations=destinations)\n",
      "\u001b[0;32m/data/anaconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow/python/distribute/cross_device_ops.py\u001b[0m in \u001b[0;36mreduce_non_distributed_value\u001b[0;34m(reduce_op, device_map, value, destinations)\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_replicas_in_graph\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     raise ValueError(\"A non-DistributedValues value %s cannot be reduced with \"\n\u001b[0;32m---> 95\u001b[0;31m                      \"the given reduce op %s.\" % (value, reduce_op))\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msimple_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A non-DistributedValues value 8 cannot be reduced with the given reduce op ReduceOp.SUM."
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    for inputs in dist_dataset:\n",
    "        train_step(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load DataSet\n",
    "tf_records = \"/data/tf_transformer_jd_data/*.tfrecord\"\n",
    "tf_records = glob.glob(tf_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf_batch_iterator(tf_records, batch_size=8, static_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#dataset = np.random.randint(500, size=(1000, 200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model from scratch.........\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.ops.summary_ops_v2.ResourceSummaryWriter at 0x7f9768119128>,\n",
       " <tensorflow.python.ops.summary_ops_v2.ResourceSummaryWriter at 0x7f96f805b2b0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Gpt(8, 768, 8, 3072, 512, 50000,\n",
    "                 optimizer=\"adam\", learning_rate=0.001)\n",
    "\n",
    "model.creat_optimizer()\n",
    "model.create_checkpoint_manager(\"../log\")\n",
    "model.create_summary_writer(\"../log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566397335.863161\n",
      "1.2475545406341553\n",
      "Step 0 Train_Loss 6.7555 Train_Accuracy 0.0000\n",
      "0.07060694694519043\n",
      "0.6756556034088135\n",
      "0.0006010532379150391\n",
      "0.5170323848724365\n",
      "0.000591278076171875\n",
      "0.39098453521728516\n",
      "0.0006031990051269531\n",
      "0.4092681407928467\n",
      "0.0005300045013427734\n",
      "0.5804312229156494\n",
      "0.0007128715515136719\n",
      "0.5376935005187988\n",
      "0.0006616115570068359\n",
      "0.5838406085968018\n",
      "0.00067901611328125\n",
      "0.5222241878509521\n",
      "0.00025582313537597656\n",
      "0.5532712936401367\n",
      "0.00027680397033691406\n",
      "0.5262517929077148\n",
      "Step 10 Train_Loss 2.9714 Train_Accuracy 0.0742\n",
      "0.0897216796875\n",
      "0.532895565032959\n",
      "0.0007557868957519531\n",
      "0.4413025379180908\n",
      "0.0006079673767089844\n",
      "0.3407862186431885\n",
      "0.00025844573974609375\n",
      "0.6690058708190918\n",
      "0.0005450248718261719\n",
      "0.5342147350311279\n",
      "0.0005323886871337891\n",
      "0.4357268810272217\n",
      "0.00054931640625\n",
      "0.6493914127349854\n",
      "0.0005395412445068359\n",
      "0.5041649341583252\n",
      "0.0005397796630859375\n",
      "0.5119156837463379\n",
      "0.0008025169372558594\n",
      "0.4587998390197754\n",
      "Step 20 Train_Loss 3.4899 Train_Accuracy 0.0493\n",
      "0.07921195030212402\n",
      "0.5602123737335205\n",
      "0.0007944107055664062\n",
      "0.549187183380127\n",
      "0.0007770061492919922\n",
      "0.5292420387268066\n",
      "0.0006270408630371094\n",
      "0.41962647438049316\n",
      "0.0008022785186767578\n",
      "0.3966655731201172\n",
      "0.0007448196411132812\n",
      "0.449993371963501\n",
      "0.0005965232849121094\n",
      "0.45770716667175293\n",
      "0.00054931640625\n",
      "0.380312442779541\n",
      "0.0004668235778808594\n",
      "0.573173999786377\n",
      "0.0007171630859375\n",
      "0.5126962661743164\n",
      "Step 30 Train_Loss 5.0179 Train_Accuracy 0.0475\n",
      "0.0704183578491211\n",
      "0.36351871490478516\n",
      "0.0005459785461425781\n",
      "0.5130534172058105\n",
      "0.000659942626953125\n",
      "0.6055786609649658\n",
      "0.0006754398345947266\n",
      "0.5486958026885986\n",
      "0.0006167888641357422\n",
      "0.5447573661804199\n",
      "0.0006611347198486328\n",
      "0.3208658695220947\n",
      "0.0005204677581787109\n",
      "0.3853309154510498\n",
      "0.0005209445953369141\n",
      "0.5209469795227051\n",
      "0.0006918907165527344\n",
      "0.5248985290527344\n",
      "0.0006566047668457031\n",
      "0.5312361717224121\n",
      "Step 40 Train_Loss 4.3331 Train_Accuracy 0.0564\n",
      "0.07241344451904297\n",
      "0.45862460136413574\n",
      "0.0005536079406738281\n",
      "0.5417640209197998\n",
      "0.0005626678466796875\n",
      "0.5745306015014648\n",
      "0.0006663799285888672\n",
      "0.37265896797180176\n",
      "0.00027251243591308594\n",
      "0.41475725173950195\n",
      "0.0005471706390380859\n",
      "0.4008147716522217\n",
      "0.0004937648773193359\n",
      "0.5026090145111084\n",
      "0.0005893707275390625\n",
      "0.45144104957580566\n",
      "0.0005772113800048828\n",
      "0.5470352172851562\n",
      "0.0007071495056152344\n",
      "0.49408459663391113\n",
      "Step 50 Train_Loss 2.8038 Train_Accuracy 0.0868\n",
      "0.07024216651916504\n",
      "0.5457572937011719\n",
      "0.0005824565887451172\n",
      "0.6486833095550537\n",
      "0.0007307529449462891\n",
      "0.6041123867034912\n",
      "0.0005481243133544922\n",
      "0.5255382061004639\n",
      "0.0005195140838623047\n",
      "0.42626476287841797\n",
      "0.0005698204040527344\n",
      "0.5991427898406982\n",
      "0.000682830810546875\n",
      "0.5390377044677734\n",
      "0.0006334781646728516\n",
      "0.5048787593841553\n",
      "0.0008175373077392578\n",
      "0.5734398365020752\n",
      "0.0006227493286132812\n",
      "0.5609946250915527\n",
      "Step 60 Train_Loss 2.4776 Train_Accuracy 0.0873\n",
      "0.07185697555541992\n",
      "0.5362417697906494\n",
      "0.0006546974182128906\n",
      "0.5264244079589844\n",
      "0.0005254745483398438\n",
      "0.5461227893829346\n",
      "0.0006477832794189453\n",
      "0.3310990333557129\n",
      "0.0004775524139404297\n",
      "0.5502898693084717\n",
      "0.0006356239318847656\n",
      "0.6499390602111816\n",
      "0.0005834102630615234\n",
      "0.6100265979766846\n",
      "0.0002815723419189453\n",
      "0.36290669441223145\n",
      "0.0005466938018798828\n",
      "0.5176534652709961\n",
      "0.0005807876586914062\n",
      "0.6413023471832275\n",
      "Step 70 Train_Loss 1.7288 Train_Accuracy 0.1014\n",
      "0.07129430770874023\n",
      "0.37506937980651855\n",
      "0.0005035400390625\n",
      "0.42284703254699707\n",
      "0.0005536079406738281\n",
      "0.5786397457122803\n",
      "0.0006487369537353516\n",
      "0.6377675533294678\n",
      "0.0003178119659423828\n",
      "0.4950556755065918\n",
      "0.0006201267242431641\n",
      "0.4992375373840332\n",
      "0.000537872314453125\n",
      "0.5335454940795898\n",
      "0.000644683837890625\n",
      "0.6072933673858643\n",
      "0.0006089210510253906\n",
      "0.5157113075256348\n",
      "0.0006494522094726562\n",
      "0.5379784107208252\n",
      "Step 80 Train_Loss 2.5465 Train_Accuracy 0.1308\n",
      "0.07081794738769531\n",
      "0.5786161422729492\n",
      "0.00029087066650390625\n",
      "0.4181351661682129\n",
      "0.0004887580871582031\n",
      "0.661801815032959\n",
      "0.00069427490234375\n",
      "0.5255515575408936\n",
      "0.0005841255187988281\n",
      "0.4934091567993164\n",
      "0.0005178451538085938\n",
      "0.5489199161529541\n",
      "0.00028395652770996094\n",
      "0.4204132556915283\n",
      "0.0005173683166503906\n",
      "0.5447649955749512\n",
      "0.0005147457122802734\n",
      "0.37129807472229004\n",
      "0.0005948543548583984\n",
      "0.45520758628845215\n",
      "Step 90 Train_Loss 2.5715 Train_Accuracy 0.0972\n",
      "0.07124209403991699\n",
      "0.40448689460754395\n",
      "0.0005619525909423828\n",
      "0.5641353130340576\n",
      "0.0004973411560058594\n",
      "0.5212197303771973\n",
      "0.0005414485931396484\n",
      "0.4534158706665039\n",
      "0.0005681514739990234\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[2, 2, 3, 0, 0, 0]]\n",
    "\n",
    "weights = tf.cast(tf.not_equal(labels, 0), tf.float32)\n",
    "outputs = [[2, 4, 3, 0, 0, 0]]\n",
    "padded_labels = tf.cast(labels, tf.int32)\n",
    "\n",
    "acc = tf.cast(tf.equal(outputs, padded_labels), tf.float32)\n",
    "\n",
    "nonpad = tf.math.count_nonzero(weights, dtype=tf.dtypes.float32,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.Mean()\n",
    "m.update_state(acc, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc*weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_sum(tf.cast(acc*weights, tf.float32))/nonpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy(labels, [[[1, 4, 6], [1, 5, 6], [1, 0, 4], [0, 0, 0], [0, 0, 0], [0, 0, 0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.argmax([[[1, 4, 2], [1, 5, 2], [1, 0, 4], [0, 0, 0], [0, 0, 0], [0, 0, 0]]], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def create_look_ahead_mask(nd, ns):\n",
    "    mask = 1-tf.linalg.band_part(tf.ones((nd, ns)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
    "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
    "    \"\"\"\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "def mask_attn_weights(w):\n",
    "    # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
    "    _, _, nd, ns = shape_list(w)\n",
    "    b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "    b = tf.reshape(b, [1, 1, nd, ns])\n",
    "    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.compat.v1.get_variable('x', [1, 2, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=mask_attn_weights(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(mask[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = attention_mask(4, 4, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_look_ahead_mask(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.reshape(m, [1, 1, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x*b - tf.cast(1e10, x.dtype)*(1-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(1e10, x.dtype)*(1-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.compat.v1.get_variable('x', [2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.concat([x, tf.zeros([2, 1])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lk = create_look_ahead_mask(5, 5)\n",
    "m = create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.maximum(m, lk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.split(x, 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_tile(value, size):\n",
    "    \"\"\"Add a new axis of given size.\"\"\"\n",
    "    value = tf.convert_to_tensor(value, name='value')\n",
    "    ndims = value.shape.ndims\n",
    "    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)\n",
    "\n",
    "def positions_for(tokens, past_length):\n",
    "    batch_size = tf.shape(tokens)[0]\n",
    "    nsteps = tf.shape(tokens)[1]\n",
    "    return expand_tile(past_length + tf.range(nsteps), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.compat.v1.get_variable('x', [1, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_for(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(tf.not_equal([[1, 1, 0], [1, 0, 0]], 0), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "batch_seq = 1\n",
    "start = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(tf.tile(tf.range(start, batch_seq + start), [batch_size]),\n",
    "                                       [batch_size, batch_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
